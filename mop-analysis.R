#----------------------------------------
# This script aims to clean Jess' data
# for MOP
#----------------------------------------

#----------------------------------------
# Author: Trent Henderson, 28 August 2020
#----------------------------------------

# Load packages

library(tidyverse)
library(data.table)
library(readxl)
library(janitor)
library(tidyLPA)
library(Cairo)
library(broom)
library(sjPlot)
library(caTools)
library(e1071)

# Turn off scientific notation

options(scipen = 999)

# Load in excel file

d <- read_excel("data/JBlower.MOrgPsych.v1.0.xlsx") %>%
  clean_names()

# Load logistic regression output function

source("R/logit_output_generator.R")

#------------------------PREP DATA-------------------------

d1 <- d %>%
  mutate(detachment = (d1 + d2 + d3 + d4)/4,
         relaxation = (r1 + r2 + r3 + r4)/4,
         mastery = (m1 + m2 + m3 + m4)/4,
         control = (c1 + c2 + c3 + c4)/4,
         consis_interest = ci1 + ci2 + ci3 + ci4,
         pers_effort = pe1 + pe2 + pe3 + pe4,
         job_demands = jd1 + jd2 + jd3 + jd4,
         workload = qwi1 + qwi2 + qwi3 + qwi4 + qwi5,
         job_control = jc1, jc2, jc3, jc4, jc5, jc6, jc7, jc8, jc9, jc10,
         engagement_vigour = vig1 + vig2 + vig3,
         engagement_dedication = ded1 + ded2 + ded3,
         engagement_absorption = abs1 + abs2 + abs3,
         burnout_exhaustion = exh1 + exh2 + exh3 + exh4 + exh5,
         burnout_cynicism = cyn1 + cyn2 + cyn3 + cyn4,
         burnout_profefficacy = eff1 + eff2 + eff3 + eff4 + eff5 + eff6,
         mental_health = (mhi1 + mhi2 + mhi3 + mhi4 + mhi5)*4,
         panas_pos = p1 + p2 + p3 + p4 + p5,
         panas_neg = n1 + n2 + n3 + n4 + n5,
         swl = swl1 + swl2 + swl3 + swl4 + swl5) %>%
  dplyr::select(c(id, gender, age, marital, kids, program, load, degree, employ, employhrs,
                  detachment, relaxation, mastery, control, consis_interest, pers_effort,
                  job_demands, workload, job_control, engagement_vigour, engagement_dedication, 
                  engagement_absorption, burnout_exhaustion, burnout_cynicism, burnout_profefficacy,
                  mental_health, panas_pos, panas_neg, swl))

#------------------------ANALYSIS--------------------------

# Drop NAs for the LPA

d2 <- d1 %>%
  #dplyr::select(c(detachment, relaxation, mastery, control)) %>%
  drop_na()

#------------------------
# LATENT PROFILE ANALYSIS
#------------------------

# Specify latent profile analysis model

m1 <- d2[1:nrow(d2), ] %>%
  select(detachment, relaxation, mastery, control) %>%
  single_imputation() %>%
  estimate_profiles(1:6,
                    variances = c("equal", "varying"),
                    covariances = c("zero", "varying"))

# Look at statistical outputs

m1 %>%
  compare_solutions(statistics = c("AIC", "BIC"))

# Plot LPA

m1 %>%
  plot_profiles()

# Get fit statistics

get_fit(m1)

# Get outputs in a dataframe

lpa_outputs <- get_data(m1)

# Filter to just Model 1/Classes 2 as this model had the best BIC value

lpa_outputs_filt <- lpa_outputs %>%
  filter(model_number == "1" & classes_number == 2)

# Join back in to main dataset

d3 <- d2 %>%
  inner_join(lpa_outputs_filt, by = c("detachment" = "detachment", "relaxation" = "relaxation",
                                      "mastery" = "mastery", "control" = "control")) %>%
  filter(Probability > 0.8) %>%
  mutate(Class = as.factor(Class)) %>%
  mutate(gender = as.factor(gender))

#------------------------
# ANALYSIS OF CLASSES
#------------------------

class_desc <- d3 %>%
  dplyr::select(c(detachment, relaxation, mastery, control, Class)) %>%
  gather(key = metric, value = value, 1:4) %>%
  mutate(metric = str_to_title(metric))

p <- class_desc %>%
  ggplot(aes(x = value)) +
  geom_density(aes(fill = Class), colour = "#05445E", alpha = 0.5) +
  labs(title = "Distribution of recovery experiences by recovery profile",
       subtitle = "Recovery profiles were generated by LPA",
       x = "Value",
       y = "Density",
       fill = "Recovery Profile") +
  scale_fill_manual(values = c("#FEB06A", "#189AB4")) +
  theme_bw() +
  theme(legend.position = "bottom",
        panel.grid.minor = element_blank()) +
  facet_wrap(~metric)
print(p)

#------------------------
# LOGISTIC REGRESSION
#------------------------

# Model build

m1_logit <- glm(Class ~ job_demands + workload + job_control + consis_interest + pers_effort,
                family = binomial(link = "logit"),
                data = d3)

# Check outliers

model.data <- augment(m1_logit) %>% 
  mutate(index = 1:n())

model.data %>% 
  top_n(3, .cooksd)

ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = Class), size = 2) +
  theme_bw()

check<- model.data %>% 
  filter(abs(.std.resid) > 3) # No significant outliers

# Check multicollinearity

car::vif(m1_logit) # VIF values are well below 5 suggesting no multicollinearity

# Check linearity of continuous predictors and logit of response variable

probabilities <- predict(m1_logit, type = "response")

d4 <- d3 %>%
  dplyr::select(c(job_demands, workload, job_control, consis_interest, pers_effort))

mydata <- d4 %>%
  mutate(logit = log(probabilities/(1-probabilities))) %>%
  gather(key = "predictors", value = "predictor.value", -logit)

ggplot(mydata, aes(logit, predictor.value))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "lm") + 
  theme_bw() + 
  facet_wrap(~predictors, scales = "free_y")

# Get outputs

tab_model(m1_logit, p.style = "asterisk")
summary(m1_logit)

# Retrieve and exponentiate coefficients

logit_outputs <- logit_output_generator(m1_logit)

logit_outputs <- logit_outputs %>%
  mutate(odds_calc = exp(estimate_log_odds),
         lower_odds = exp(lower_log_odds),
         upper_odds = exp(upper_log_odds))

chart_data <- logit_outputs %>%
  mutate(measure = case_when(
         measure == "job_demands"     ~ "Job Demands",
         measure == "workload"        ~ "Workload",
         measure == "job_control"     ~ "Job Control",
         measure == "consis_interest" ~ "Grit",
         measure == "pers_effort"     ~ "Perseverance of Effort",
         TRUE                         ~ measure)) %>%
  filter(measure != "(Intercept)") %>%
  mutate(measure = as.factor(measure))

# Data visualisation

the_palette <- c("Significant" = "#FEB06A",
                 "Non-significant" = "#189AB4")

all_measures <- (length(chart_data$measure)+0.5)

p1 <- chart_data %>%
  ggplot(aes(y = measure, x = lower_odds, xend = upper_odds, yend = measure)) +
  geom_segment(aes(colour = sig_indicator, group = measure), size = 5) +
  geom_point(aes(x = odds_calc, y = measure), colour = "#A0E7E5", size = 4) +
  geom_vline(xintercept = 1, colour = "#05445E", lty = 2) +
  annotate("text", x = 0.70, y = all_measures, label  = "Decreased odds of Profile 2", 
           colour = "#05445E", hjust = 0.5, fontface = "bold", size = 3) +
  annotate("text", x = 1.5, y = all_measures, label  = "Increased odds of Profile 2", 
           colour = "#05445E", hjust = 0.5, fontface = "bold", size = 3) +
  labs(title = "Logistic regression output for predictors of LPA-generated recovery profiles",
       subtitle = "LPA model returned 2 recovery profiles (classes)",
       x = "Odds",
       y = "Measure",
       colour = NULL) +
  theme_bw() +
  theme(legend.position = "bottom",
        panel.grid.minor = element_blank()) +
  scale_colour_manual(values = the_palette)
print(p1)

#------------------------
# ANALYSIS OF OUTCOMES
#------------------------

# Check distributions of response variables

d3 %>%
  dplyr::select(c(engagement_vigour, engagement_dedication, 
                  engagement_absorption, burnout_exhaustion, burnout_cynicism, burnout_profefficacy,
                  mental_health, panas_pos, panas_neg, swl)) %>%
  gather(key = metric, value = value, 1:10) %>%
  mutate(metric = str_to_title(metric)) %>%
  mutate(value = log(value)) %>% # Comment out to view raw data
  ggplot(aes(x = value)) +
  geom_density(fill = "#189AB4", colour = "#05445E", alpha = 0.5) +
  labs(title = "Distributions response variables",
       x = "Value",
       y = "Density") +
  scale_fill_manual(values = c("#FEB06A", "#189AB4")) +
  theme_bw() +
  theme(legend.position = "bottom",
        panel.grid.minor = element_blank()) +
  facet_wrap(~metric)


# Build linear model

out_m1 <- lm(engagement_vigour ~ Class + gender + age + employhrs, data = d3)
out_m2 <- lm(engagement_dedication ~ Class + gender + age + employhrs, data = d3)
out_m3 <- lm(engagement_absorption ~ Class + gender + age + employhrs, data = d3)
out_m4 <- lm(burnout_exhaustion ~ Class + gender + age + employhrs, data = d3) # Significant
out_m5 <- lm(burnout_cynicism ~ Class + gender + age + employhrs, data = d3) # Significant
out_m6 <- lm(burnout_profefficacy ~ Class + gender + age + employhrs, data = d3)
out_m7 <- lm(mental_health ~ Class + gender + age + employhrs, data = d3) # Significant
out_m8 <- lm(panas_pos ~ Class + gender + age + employhrs, data = d3)
out_m9 <- lm(panas_neg ~ Class + gender + age + employhrs, data = d3) # Significant
out_m10 <- lm(swl ~ Class + gender + age + employhrs, data = d3) # Significant

# Output tables

tab_model(out_m1, out_m2, out_m3, out_m4, out_m5, p.style = "asterisk")
tab_model(out_m6, out_m7, out_m8, out_m9, out_m10, p.style = "asterisk")

# Model outputs

adj_pval <- 0.05 / 10 # Bonferroni correction

stat_production <- function(stat_model){
  stat_model <- tidy(stat_model) %>%
    mutate(Significance = case_when(
      p.value < adj_pval ~ "Significant effect",
      TRUE               ~ "Non-significant effect")) %>%
    filter(!grepl("Intercept", term)) %>%
    mutate(p.value = round(p.value, digits = 3),
           estimate = round(estimate, digits = 2),
           std.error = round(std.error, digits = 2),
           statistic = round(statistic, digits = 2)) %>%
    rename("p-value" = p.value) %>%
    rename("Coefficient point estimate" = estimate) %>%
    rename("SE" = std.error) %>%
    rename("t" = statistic) %>%
    rename("Explanatory variable" = term)
}

m1_clean <- stat_production(out_m1) %>% mutate("Response variable" = "Engagement (Vigour)")
m2_clean <- stat_production(out_m2) %>% mutate("Response variable" = "Engagement (Dedication)")
m3_clean <- stat_production(out_m3) %>% mutate("Response variable" = "Engagement (Absorption)")
m4_clean <- stat_production(out_m4) %>% mutate("Response variable" = "Burnout (Exhaustion)")
m5_clean <- stat_production(out_m5) %>% mutate("Response variable" = "Burnout (Cynicism)")
m6_clean <- stat_production(out_m6) %>% mutate("Response variable" = "Burnout (Professional Efficacy)")
m7_clean <- stat_production(out_m7) %>% mutate("Response variable" = "Mental Health")
m8_clean <- stat_production(out_m8) %>% mutate("Response variable" = "PANAS (Positive Affect)")
m9_clean <- stat_production(out_m9) %>% mutate("Response variable" = "PANAS (Negative Affect")
m10_clean <- stat_production(out_m10) %>% mutate("Response variable" = "Satisfaction with Life")

all_models <- bind_rows(m1_clean, m2_clean, m3_clean, m4_clean, m5_clean, 
                        m6_clean, m7_clean, m8_clean, m9_clean, m10_clean) %>%
  dplyr::select(-c(1)) %>%
  mutate("Explanatory variable" = "Recovery Profile")

#------------------------EXPORTS---------------------------

# Descriptive plot

CairoPNG("output/distributions.png", 800, 600)
print(p)
dev.off()

# Logit plot

CairoPNG("output/logit-model.png", 900, 600)
print(p1)
dev.off()
